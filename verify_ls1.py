#!/usr/bin/env python3
import os
import subprocess
import re
import time
import glob
import shutil
from typing import Dict, List, Tuple

def extract_optimal_solution(output_file: str) -> int:
    """
    Extract the optimal solution quality from the .out file.
    
    Args:
        output_file: Path to the output file
        
    Returns:
        Optimal solution quality (number of sets in optimal solution)
    """
    try:
        with open(output_file, 'r') as f:
            # The first line should contain the solution quality (number of sets)
            first_line = f.readline().strip()
            return int(first_line)
    except Exception as e:
        print(f"Error reading optimal solution file {output_file}: {e}")
        return None

def extract_ls_solution_quality(solution_file: str) -> int:
    """
    Extract the solution quality from the LS1 solution file.
    
    Args:
        solution_file: Path to the solution file generated by LS1
        
    Returns:
        Solution quality (number of sets in solution)
    """
    try:
        with open(solution_file, 'r') as f:
            # The first line should contain the solution quality
            first_line = f.readline().strip()
            return int(first_line)
    except Exception as e:
        print(f"Error reading LS solution file {solution_file}: {e}")
        return None

def run_ls1_on_instance(instance_file: str, timeout: int, seed: int, results_dir: str) -> Tuple[int, float, str, str]:
    """
    Run the LS1 algorithm on the given instance.
    
    Args:
        instance_file: Path to the instance file
        timeout: Cutoff time in seconds
        seed: Random seed
        results_dir: Directory to store results
        
    Returns:
        Tuple of (solution quality, runtime in seconds, solution file path, trace file path)
    """
    start_time = time.time()
    instance_name = os.path.basename(instance_file).split('.')[0]
    
    # Create directory for this instance's results
    instance_results_dir = os.path.join(results_dir, instance_name)
    os.makedirs(instance_results_dir, exist_ok=True)
    
    # Define output paths
    output_prefix = f"solutions/LS1/{instance_name}_LS1_{timeout}_{seed}"
    
    # Make sure the solutions directory exists
    os.makedirs(os.path.dirname(output_prefix), exist_ok=True)
    
    # Run the LS1 algorithm
    cmd = [
        "python", "local_search.py",
        "-inst", instance_file,
        "-alg", "LS1",
        "-time", str(timeout),
        "-seed", str(seed)
    ]
    
    try:
        result = subprocess.run(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            text=True,
            timeout=timeout + 10  # Give a little extra time for the process to complete
        )
        
        if result.returncode != 0:
            print(f"Error running LS1 on {instance_file}: {result.stderr}")
            return None, time.time() - start_time, None, None
        
        # Solution and trace file paths
        solution_file = f"{output_prefix}.sol"
        trace_file = f"{output_prefix}.trace"
        
        # Copy solution and trace files to the instance results directory
        solution_dest = os.path.join(instance_results_dir, f"{instance_name}_LS1_{timeout}_{seed}.sol")
        trace_dest = os.path.join(instance_results_dir, f"{instance_name}_LS1_{timeout}_{seed}.trace")
        
        shutil.copy(solution_file, solution_dest)
        shutil.copy(trace_file, trace_dest)
        
        # Extract quality from the solution file
        quality = extract_ls_solution_quality(solution_file)
        
        return quality, time.time() - start_time, solution_dest, trace_dest
    except subprocess.TimeoutExpired:
        print(f"LS1 timed out on {instance_file}")
        return None, timeout + 10, None, None
    except Exception as e:
        print(f"Error running LS1 on {instance_file}: {e}")
        return None, time.time() - start_time, None, None

def verify_all_instances(data_dir: str = "data", results_dir: str = "solutions/small", timeout: int = 60, seed: int = 42) -> None:
    """
    Verify all test instances in the given directory and store results.
    
    Args:
        data_dir: Directory containing test instances
        results_dir: Directory to store the results
        timeout: Cutoff time in seconds for each instance
        seed: Random seed
    """
    # Create results directory
    os.makedirs(results_dir, exist_ok=True)
    
    # Find all small files (corrected pattern)
    test_files = glob.glob(os.path.join(data_dir, "small*.in"))
    
    if not test_files:
        print(f"No small*.in files found in {data_dir}")
        return
    
    results = []
    
    print(f"Found {len(test_files)} test files.")
    print("-" * 80)
    print(f"{'Instance':<20} {'Optimal':<10} {'LS1':<10} {'Gap':<10} {'Time (s)':<10} {'Result'}")
    print("-" * 80)
    
    # Create master results summary file
    master_summary_file = os.path.join(results_dir, "verification_results.txt")
    
    for instance_file in sorted(test_files):
        instance_name = os.path.basename(instance_file).split('.')[0]
        
        # Find corresponding output file
        output_file = instance_file.replace(".in", ".out")
        
        if not os.path.exists(output_file):
            print(f"Output file not found for {instance_name}, skipping.")
            continue
        
        # Extract optimal solution
        optimal_quality = extract_optimal_solution(output_file)
        
        if optimal_quality is None:
            print(f"Could not extract optimal solution for {instance_name}, skipping.")
            continue
        
        # Run LS1
        ls1_quality, runtime, solution_file, trace_file = run_ls1_on_instance(instance_file, timeout, seed, results_dir)
        
        # Create instance results directory if it doesn't exist
        instance_results_dir = os.path.join(results_dir, instance_name)
        os.makedirs(instance_results_dir, exist_ok=True)
        
        # Copy the input and output files to the instance results directory
        shutil.copy(instance_file, os.path.join(instance_results_dir, f"{instance_name}.in"))
        shutil.copy(output_file, os.path.join(instance_results_dir, f"{instance_name}.out"))
        
        if ls1_quality is None:
            print(f"{instance_name:<20} {optimal_quality:<10} {'N/A':<10} {'N/A':<10} {runtime:<10.2f} FAILED")
            results.append((instance_name, optimal_quality, None, None, runtime, "FAILED", None, None))
            continue
        
        # Calculate gap
        gap = ((ls1_quality - optimal_quality) / optimal_quality) * 100.0 if optimal_quality > 0 else float('inf')
        
        # Determine result
        result = "OPTIMAL" if ls1_quality == optimal_quality else "SUB-OPT"
        
        print(f"{instance_name:<20} {optimal_quality:<10} {ls1_quality:<10} {gap:<10.2f}% {runtime:<10.2f} {result}")
        results.append((instance_name, optimal_quality, ls1_quality, gap, runtime, result, solution_file, trace_file))
        
        # Create individual result summary file for this instance
        instance_summary_file = os.path.join(instance_results_dir, f"{instance_name}_summary.txt")
        with open(instance_summary_file, "w") as f:
            f.write(f"Instance: {instance_name}\n")
            f.write(f"Optimal solution: {optimal_quality}\n")
            f.write(f"LS1 solution: {ls1_quality}\n")
            f.write(f"Gap: {gap:.2f}%\n")
            f.write(f"Runtime: {runtime:.2f} seconds\n")
            f.write(f"Result: {result}\n")
    
    print("-" * 80)
    
    # Summary
    optimal_count = sum(1 for _, _, _, _, _, result, _, _ in results if result == "OPTIMAL")
    subopt_count = sum(1 for _, _, _, _, _, result, _, _ in results if result == "SUB-OPT")
    failed_count = sum(1 for _, _, _, _, _, result, _, _ in results if result == "FAILED")
    
    print(f"\nSummary:")
    print(f"Total instances: {len(results)}")
    print(f"Optimal solutions: {optimal_count}")
    print(f"Sub-optimal solutions: {subopt_count}")
    print(f"Failed runs: {failed_count}")
    
    if subopt_count > 0:
        avg_gap = sum(gap for _, _, _, gap, _, result, _, _ in results if result == "SUB-OPT" and gap is not None) / subopt_count
        print(f"Average gap for sub-optimal solutions: {avg_gap:.2f}%")
    
    print(f"\nResults saved to '{master_summary_file}'")
    
    # Save master results summary to file
    with open(master_summary_file, "w") as f:
        f.write(f"Verification Results - LS1 Algorithm\n")
        f.write(f"Timeout: {timeout} seconds, Seed: {seed}\n")
        f.write("-" * 80 + "\n")
        f.write(f"{'Instance':<20} {'Optimal':<10} {'LS1':<10} {'Gap':<10} {'Time (s)':<10} {'Result'}\n")
        f.write("-" * 80 + "\n")
        
        for instance_name, optimal, ls1, gap, runtime, result, _, _ in results:
            if ls1 is None:
                f.write(f"{instance_name:<20} {optimal:<10} {'N/A':<10} {'N/A':<10} {runtime:<10.2f} {result}\n")
            else:
                f.write(f"{instance_name:<20} {optimal:<10} {ls1:<10} {gap:<10.2f}% {runtime:<10.2f} {result}\n")
        
        f.write("-" * 80 + "\n")
        f.write(f"\nSummary:\n")
        f.write(f"Total instances: {len(results)}\n")
        f.write(f"Optimal solutions: {optimal_count}\n")
        f.write(f"Sub-optimal solutions: {subopt_count}\n")
        f.write(f"Failed runs: {failed_count}\n")
        
        if subopt_count > 0:
            avg_gap = sum(gap for _, _, _, gap, _, result, _, _ in results if result == "SUB-OPT" and gap is not None) / subopt_count
            f.write(f"Average gap for sub-optimal solutions: {avg_gap:.2f}%\n")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Verify LS1 algorithm against optimal solutions")
    parser.add_argument("--data-dir", default="data", help="Directory containing test instances")
    parser.add_argument("--results-dir", default="solutions/small", help="Directory to store results")
    parser.add_argument("--timeout", type=int, default=60, help="Timeout in seconds for each instance")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    
    args = parser.parse_args()
    
    verify_all_instances(args.data_dir, args.results_dir, args.timeout, args.seed)